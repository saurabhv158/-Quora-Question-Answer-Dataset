{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoZwl6LRwAhwAriR4Krub1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkblykPzNdv_","executionInfo":{"status":"ok","timestamp":1722018756677,"user_tz":-330,"elapsed":3750,"user":{"displayName":"Hacker Group","userId":"10341260174900033697"}},"outputId":"d738f791-56b0-4fd2-ebc8-0af22802ed60"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                            question  \\\n","0  Why whenever I get in the shower my girlfriend...   \n","1            What is a proxy, and how can I use one?   \n","2  What song has the lyrics \"someone left the cak...   \n","3  I am the owner of an adult website called http...   \n","4  Does the Bible mention anything about a place ...   \n","\n","                                              answer  \n","0  Isn’t it awful? You would swear that there was...  \n","1  A proxy server is a system or router that prov...  \n","2                                 MacArthur's Park\\n  \n","3  Don't let apps that are liers put adds on your...  \n","4  St. John in the book of Revelation mentions an...  \n"]}],"source":["import pandas as pd\n","\n","df = pd.read_json(\"hf://datasets/toughdata/quora-question-answer-dataset/Quora-QuAD.jsonl\", lines=True)\n","\n","# Display the first few rows of the dataframe\n","print(df.head())"]},{"cell_type":"code","source":["# Display the first few rows of the dataframe\n","print(\"First few rows of the dataset:\")\n","print(df.head())\n","\n","# Display the columns of the dataframe\n","print(\"\\nColumns in the dataset:\")\n","print(df.columns)\n","\n","# Display basic information about the dataframe\n","print(\"\\nBasic information about the dataset:\")\n","print(df.info())\n","\n","# Display descriptive statistics\n","print(\"\\nDescriptive statistics of the dataset:\")\n","print(df.describe())\n","\n","# Display a few sample rows\n","print(\"\\nSample rows from the dataset:\")\n","print(df.sample(5))\n","\n","# List of columns to drop (this list is hypothetical and should be adjusted based on actual data inspection)\n","columns_to_drop = ['id', 'url', 'created_at', 'updated_at']\n","\n","# Drop irrelevant columns\n","df_cleaned = df.drop(columns=columns_to_drop, errors='ignore')\n","\n","# Display the first few rows of the cleaned dataframe\n","print(\"\\nFirst few rows of the cleaned dataset:\")\n","print(df_cleaned.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMoDR1thQOwe","executionInfo":{"status":"ok","timestamp":1722018762276,"user_tz":-330,"elapsed":462,"user":{"displayName":"Hacker Group","userId":"10341260174900033697"}},"outputId":"466ca267-2b1b-41eb-ae86-999630bf27a3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["First few rows of the dataset:\n","                                            question  \\\n","0  Why whenever I get in the shower my girlfriend...   \n","1            What is a proxy, and how can I use one?   \n","2  What song has the lyrics \"someone left the cak...   \n","3  I am the owner of an adult website called http...   \n","4  Does the Bible mention anything about a place ...   \n","\n","                                              answer  \n","0  Isn’t it awful? You would swear that there was...  \n","1  A proxy server is a system or router that prov...  \n","2                                 MacArthur's Park\\n  \n","3  Don't let apps that are liers put adds on your...  \n","4  St. John in the book of Revelation mentions an...  \n","\n","Columns in the dataset:\n","Index(['question', 'answer'], dtype='object')\n","\n","Basic information about the dataset:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 56402 entries, 0 to 56401\n","Data columns (total 2 columns):\n"," #   Column    Non-Null Count  Dtype \n","---  ------    --------------  ----- \n"," 0   question  56402 non-null  object\n"," 1   answer    56402 non-null  object\n","dtypes: object(2)\n","memory usage: 881.4+ KB\n","None\n","\n","Descriptive statistics of the dataset:\n","                                                 question answer\n","count                                               56402  56402\n","unique                                               3234  54726\n","top     Would Hillary Clinton have made a better Presi...   No\\n\n","freq                                                  106     89\n","\n","Sample rows from the dataset:\n","                                                question  \\\n","38608                What puzzles you most about humans?   \n","25183  Why is Weedmaps asking for a medical card when...   \n","46712  Do dogs have growth spurts after they're fully...   \n","32506  What is wrong with my washing machine? It fill...   \n","37172  What do Australians and New Zealanders dislike...   \n","\n","                                                  answer  \n","38608            How messed up people treat each other\\n  \n","25183  Marijuana is legal in California. However, the...  \n","46712  Google LLC is an American multinational techno...  \n","32506  Q: What is wrong with my washer machine? It fi...  \n","37172  How hard it is for people from other nationali...  \n","\n","First few rows of the cleaned dataset:\n","                                            question  \\\n","0  Why whenever I get in the shower my girlfriend...   \n","1            What is a proxy, and how can I use one?   \n","2  What song has the lyrics \"someone left the cak...   \n","3  I am the owner of an adult website called http...   \n","4  Does the Bible mention anything about a place ...   \n","\n","                                              answer  \n","0  Isn’t it awful? You would swear that there was...  \n","1  A proxy server is a system or router that prov...  \n","2                                 MacArthur's Park\\n  \n","3  Don't let apps that are liers put adds on your...  \n","4  St. John in the book of Revelation mentions an...  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer, WordNetLemmatizer\n","\n","# Download necessary NLTK data files\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Initialize the tools\n","stop_words = set(stopwords.words('english'))\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess_text(text):\n","    # Tokenization\n","    tokens = word_tokenize(text)\n","\n","    # Stop word removal\n","    tokens = [word for word in tokens if word.lower() not in stop_words]\n","\n","    # Stemming (use lemmatizer instead of stemming if preferred)\n","    # stemmed_tokens = [stemmer.stem(word) for word in tokens]\n","\n","    # Lemmatization\n","    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","\n","    return lemmatized_tokens\n","\n","# Apply preprocessing to each question\n","df_cleaned['processed_questions'] = df_cleaned['question'].apply(preprocess_text)\n","\n","# Display the processed DataFrame\n","print(df_cleaned.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDrNrnIjQfC9","executionInfo":{"status":"ok","timestamp":1722018826274,"user_tz":-330,"elapsed":12418,"user":{"displayName":"Hacker Group","userId":"10341260174900033697"}},"outputId":"6284a0bd-70d7-4308-c774-c6caaeceab4e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["                                            question  \\\n","0  Why whenever I get in the shower my girlfriend...   \n","1            What is a proxy, and how can I use one?   \n","2  What song has the lyrics \"someone left the cak...   \n","3  I am the owner of an adult website called http...   \n","4  Does the Bible mention anything about a place ...   \n","\n","                                              answer  \\\n","0  Isn’t it awful? You would swear that there was...   \n","1  A proxy server is a system or router that prov...   \n","2                                 MacArthur's Park\\n   \n","3  Don't let apps that are liers put adds on your...   \n","4  St. John in the book of Revelation mentions an...   \n","\n","                                 processed_questions  \n","0  [whenever, get, shower, girlfriend, want, join...  \n","1                            [proxy, ,, use, one, ?]  \n","2  [song, lyric, ``, someone, left, cake, rain, '...  \n","3  [owner, adult, website, called, http, :, //mat...  \n","4  [Bible, mention, anything, place, ``, '', heav...  \n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","# Define the model names\n","model_names = [\"bert-base-uncased\", \"t5-base\", \"gpt2\"]\n","\n","# Load the tokenizers\n","tokenizers = {name: AutoTokenizer.from_pretrained(name) for name in model_names}\n","\n","# Tokenize the questions\n","df_cleaned['tokenized_questions'] = df_cleaned['question'].apply(lambda x: {name: tokenizers[name](x, return_tensors='pt') for name in model_names})\n","\n","print(df_cleaned['tokenized_questions'].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bslCuQhzRCEa","executionInfo":{"status":"ok","timestamp":1722018891682,"user_tz":-330,"elapsed":36712,"user":{"displayName":"Hacker Group","userId":"10341260174900033697"}},"outputId":"c2f75b25-7cd4-4889-a4f9-259c00ed2001"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0    {'bert-base-uncased': ['input_ids', 'token_typ...\n","1    {'bert-base-uncased': ['input_ids', 'token_typ...\n","2    {'bert-base-uncased': ['input_ids', 'token_typ...\n","3    {'bert-base-uncased': ['input_ids', 'token_typ...\n","4    {'bert-base-uncased': ['input_ids', 'token_typ...\n","Name: tokenized_questions, dtype: object\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n","\n","# Load the models\n","bert_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","t5_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n","gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n","\n","# Define a function to get model outputs\n","def get_model_outputs(tokenized_input, model, tokenizer, model_type):\n","    if model_type == \"bert\":\n","        outputs = model(**tokenized_input).logits.argmax(dim=-1)\n","    elif model_type == \"t5\":\n","        input_ids = tokenized_input['input_ids']\n","        outputs = model.generate(input_ids)\n","    elif model_type == \"gpt\":\n","        input_ids = tokenized_input['input_ids']\n","        outputs = model.generate(input_ids, max_length=50)\n","\n","    decoded_outputs = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n","    return decoded_outputs\n","\n","# Apply the models to the tokenized questions\n","df_cleaned['bert_outputs'] = df_cleaned['tokenized_questions'].apply(lambda x: get_model_outputs(x[\"bert-base-uncased\"], bert_model, tokenizers[\"bert-base-uncased\"], \"bert\"))\n","df_cleaned['t5_outputs'] = df_cleaned['tokenized_questions'].apply(lambda x: get_model_outputs(x[\"t5-base\"], t5_model, tokenizers[\"t5-base\"], \"t5\"))\n","df_cleaned['gpt_outputs'] = df_cleaned['tokenized_questions'].apply(lambda x: get_model_outputs(x[\"gpt2\"], gpt_model, tokenizers[\"gpt2\"], \"gpt\"))\n","\n","print(df_cleaned[['questions', 'bert_outputs', 't5_outputs', 'gpt_outputs']])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQjfVSsnRLLX","outputId":"9c8c6317-c65a-4d26-dcf0-5404a300b8e7"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["pip install nltk rouge-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLbb5RdeSlSb","executionInfo":{"status":"ok","timestamp":1722018331663,"user_tz":-330,"elapsed":5808,"user":{"displayName":"Hacker Group","userId":"10341260174900033697"}},"outputId":"19bc0e83-a9fd-470d-8654-83a602595d94"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=a2c2621364d423e9a13175be4fd610de775df33b3943436ca6d151c5a79b333b\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","from nltk.tokenize import word_tokenize\n","from rouge_score import rouge_scorer\n","from sklearn.metrics import f1_score\n","import numpy as np\n","\n","# Function to compute BLEU score\n","def compute_bleu(reference, hypothesis):\n","    smoothing_function = SmoothingFunction().method1\n","    return sentence_bleu([reference], hypothesis, smoothing_function=smoothing_function)\n","\n","# Function to compute ROUGE score\n","def compute_rouge(reference, hypothesis):\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n","    scores = scorer.score(reference, hypothesis)\n","    return scores\n","\n","# Function to compute F1 score\n","def compute_f1(reference, hypothesis):\n","    reference_set = set(reference)\n","    hypothesis_set = set(hypothesis)\n","    common_tokens = reference_set.intersection(hypothesis_set)\n","    if len(reference_set) == 0 or len(hypothesis_set) == 0:\n","        return 0.0\n","    precision = len(common_tokens) / len(hypothesis_set)\n","    recall = len(common_tokens) / len(reference_set)\n","    if precision + recall == 0:\n","        return 0.0\n","    f1 = 2 * precision * recall / (precision + recall)\n","    return f1\n","\n","# Compute metrics for each model\n","for model in ['bert', 't5', 'gpt']:\n","    bleu_scores = []\n","    rouge_scores = []\n","    f1_scores = []\n","\n","    for idx, row in df_cleaned.iterrows():\n","        reference = row['tokenized_answers']\n","        hypothesis = word_tokenize(row[f'{model}_outputs'].lower())\n","\n","        # Compute BLEU score\n","        bleu_score = compute_bleu(reference, hypothesis)\n","        bleu_scores.append(bleu_score)\n","\n","        # Compute ROUGE score\n","        rouge_score = compute_rouge(' '.join(reference), ' '.join(hypothesis))\n","        rouge_scores.append(rouge_score)\n","\n","        # Compute F1 score\n","        f1 = compute_f1(reference, hypothesis)\n","        f1_scores.append(f1)\n","\n","    df_cleaned[f'{model}_bleu'] = bleu_scores\n","    df_cleaned[f'{model}_rouge'] = rouge_scores\n","    df_cleaned[f'{model}_f1'] = f1_scores\n","\n","# Display the DataFrame with computed metrics\n","print(df_cleaned[['question', 'bert_bleu', 't5_bleu', 'gpt_bleu']])\n","print(df_cleaned[['question', 'bert_rouge', 't5_rouge', 'gpt_rouge']])\n","print(df_cleaned[['question', 'bert_f1', 't5_f1', 'gpt_f1']])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"sdZu8BU0Smfv","executionInfo":{"status":"error","timestamp":1722018561124,"user_tz":-330,"elapsed":484,"user":{"displayName":"Hacker Group","userId":"10341260174900033697"}},"outputId":"a19b1f39-c3dd-439a-b2f7-8dbb8068b160"},"execution_count":11,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'tokenized_answers'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'tokenized_answers'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a8456d354735>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_answers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{model}_outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'tokenized_answers'"]}]}]}